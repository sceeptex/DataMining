{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below if you are using Google Colab to mount your Google Drive in your Colab instance. Adjust the path to the files in your Google Drive as needed if it differs.\n",
    "\n",
    "If you do not use Google Colab, running the cell will simply do nothing, so do not worry about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "    %cd 'drive/My Drive/Colab Notebooks/02_Clustering'\n",
    "except ImportError as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 8: Cluster Analysis\n",
    "\n",
    "### 8.1. Analyzing the Customer Data Set\n",
    "\n",
    "#### 8.1.1 Load the customers dataset from the Excel file provided in ILIAS.\n",
    "Load the excel file into a dataframe and inspect the first few records.\n",
    "Remember to import the pandas package first! Then, call the ```read_excel()``` function to load the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas\n",
    "\n",
    "\n",
    "# load the file using the read_excel() function\n",
    "\n",
    "\n",
    "# show the first few records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 8.1.2 Cluster the dataset using K-Means clustering. \n",
    "\n",
    "8.1.2.1. Experiment with different K values. Which values do make sense? \n",
    "\n",
    "8.1.2.2. What does the clustering tell you concerning your product portfolio? \n",
    "\n",
    "8.1.2.3. What does the clustering tell you concerning your marketing efforts in different regions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#####  8.1.2.1 Cluster the dataset using K-Means clustering. Experiment with different K values. \n",
    "\n",
    "The dataset contains five attributes: a customer ID and zip code as well as the number of bought and returned items for different products.\n",
    "For our analysis, we must first think about the meaning of these attributes and how we should use them.\n",
    "\n",
    "The customer id identifies individual customers and is otherwise just a number with no meaning, so we will exclude it.\n",
    "The question asks us to generate insights about our product portfolio and the performance in different regions, so we will use zip code and product for the interpretation of our results.\n",
    "That leaves us with the two attributes items bought and items returned, which contain the factual data about our business.\n",
    "It seems hence reasonable to use these two attributes for the clustering (also, using only two attributes allows us to plot everything in this exercise).\n",
    "\n",
    "Before using the selected attributes, we normalise their values into the same range to make sure that each attribute has the same importance when calculating the distance between the records.\n",
    "\n",
    "To solve the task, we do the following:\n",
    "- Cluster on the attributes ```ItemsBought``` and ```ItemsReturned```\n",
    "- Visualize (Scatter) the clustering using ```ItemsBought``` and ```ItemsReturned``` for the x and y-axes, and the cluster id for the color of the data points.\n",
    "- repeat the clustering for different K values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import KMeans\n",
    "\n",
    "\n",
    "# import matplotlib\n",
    "\n",
    "\n",
    "# import preprocessing\n",
    "\n",
    "\n",
    "# create the normaliser\n",
    "\n",
    "\n",
    "# copy the dataframe before preprocessing so we can access the original values later\n",
    "\n",
    "\n",
    "# preprocess the features ItemsBought and ItemsReturned\n",
    "\n",
    "\n",
    "# setup a figure\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# iterate over all values that we want to test for K\n",
    "for i in range(1,7):\n",
    "    # create the clusterer\n",
    "\n",
    "    \n",
    "    # create the clustering\n",
    "\n",
    "\n",
    "    # add a subplot\n",
    "    plt.subplot(3,2,i)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # setup the labels of the subplot\n",
    "    plt.title(\"#clusters (K) = {}\".format(i))\n",
    "    plt.xlabel('ItemsBought')\n",
    "    plt.ylabel('ItemsReturned')\n",
    "    \n",
    "    # create the scatter plot\n",
    "\n",
    "\n",
    "# show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Which K value(s) make sense and how would you label the resulting clusters?\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#####  8.1.2.3 What does the clustering tell you concerning your product portfolio?\n",
    "\n",
    "Run the clustering again with ```K=3```. Add the product ids to the plot using the ```annotate()``` function and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the clusterer for K = 3\n",
    "\n",
    "\n",
    "# create the clustering\n",
    "\n",
    "\n",
    "# create a scatter plot\n",
    "\n",
    "\n",
    "# annotate each data point with its product id\n",
    "\n",
    "    \n",
    "# setup the labels of the plot\n",
    "plt.xlabel('ItemsBought')\n",
    "plt.ylabel('ItemsReturned')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#####  8.1.2.4 What does the clustering tell you concerning your marketing efforts in different regions?\n",
    "\n",
    "To answer this question, we simply plot again, but this time annotate the clusters with the zip code of the respective customers.\n",
    "Note that we can use the original dataset instead of the preprocessed one for plotting and still use the clusters created on the preprocessed data, as both datasets have the same ordering of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the scatter plot\n",
    "\n",
    "\n",
    "# annotate each data point with the zip code value\n",
    "\n",
    "    \n",
    "# setup the plot labels\n",
    "plt.xlabel('ItemsBought')\n",
    "plt.ylabel('ItemsReturned')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 8.1.3 Cluster the data set using Agglomerative Hierarchical Clustering. What does the dendrogram tell you concerning your customer groups?\n",
    "\n",
    "To plot a dendrogram, we need to use the ```linkage()``` function from scipy instead of the clusterer from scikit-learn.\n",
    "After creating the clustering with the ```linkage()``` function, we can plot using the ```dendrogram()``` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import linkage and dendrogram from scipy\n",
    "\n",
    "\n",
    "# create the clustering\n",
    "\n",
    "\n",
    "# plot the dendrogram\n",
    "\n",
    "\n",
    "# setup the labels\n",
    "plt.xlabel('Customer IDs')\n",
    "plt.ylabel('distance')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Judging by the dendrogram, the customers in the \"bad\" group (IDs 8, 9 and 14) are far more different from the other customers than the customers in the \"good\" and \"average\" group (look at the Y axis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 8.1.4 Flatten the hierarchical clustering so that you get 3 or 4 customer groups. Name these groups with appropriate labels.\n",
    "\n",
    "To create a partitional clustering from a hierarchical clustering, we have to cut the hierarchy.\n",
    "You can do this in the ```dendrogram()``` function using the ```truncate_mode``` parameter.\n",
    "To create cluster ids as in KMeans, use the [```fcluster()``` function](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.fcluster.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fcluster\n",
    "\n",
    "\n",
    "# setup a figure\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# iterate over the different numbers of clusters that we want to consider (here: 3 and 4)\n",
    "counter = 1\n",
    "for i in [3,4]:\n",
    "    # add a sub plot\n",
    "    plt.subplot(2,2,counter)\n",
    "    counter += 1\n",
    "    \n",
    "    # setup the layout of the plot\n",
    "    plt.tight_layout()\n",
    "    plt.title('Dendrogram - {} clusters'.format(i))\n",
    "    plt.xlabel('Count of Customers')\n",
    "    plt.ylabel('distance')\n",
    "    \n",
    "    # plot the dendrogram\n",
    "    \n",
    "    \n",
    "    # add a second sub plot\n",
    "    plt.subplot(2,2,counter)\n",
    "    counter += 1\n",
    "    \n",
    "    # create the clusters by cutting the hierarchy\n",
    "    \n",
    "    \n",
    "    # create a scatter plot coloured according to the clusteres\n",
    "    \n",
    "    \n",
    "    # setup the plot labels\n",
    "    plt.xlabel('ItemsBought')\n",
    "    plt.ylabel('ItemsReturned')\n",
    "    \n",
    "# show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 8.2. Analyzing the Students Data Set\n",
    "\n",
    "#### 8.2.1. Aggregate the students data set by student and calculate the average mark and the average number of attended classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the excel file into a dataframe\n",
    "\n",
    "\n",
    "# show the first few records\n",
    "\n",
    "\n",
    "# group the dataframe by student name and calculate the mean values\n",
    "\n",
    "\n",
    "# show the first few records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 8.2.2 Cluster the data set using the K-Means algorithm. Does one attribute dominate the clustering? What can you do about this? Assign suitable labels to your clusters.\n",
    "\n",
    "Run a KMeans clusterer on the data and plot it in a scatter plot. Its a good idea to annotate the data points with the names of the students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the clusterer\n",
    "\n",
    "\n",
    "# create the clustering\n",
    "\n",
    "\n",
    "# create the scatter plot\n",
    "\n",
    "\n",
    "# setup the labels\n",
    "plt.xlabel(\"Attended classes\")\n",
    "plt.ylabel(\"Mark\")\n",
    "\n",
    "# annotate each data point with the name of the student\n",
    "\n",
    "\n",
    "# show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 8.2.3. Cluster the data set using Agglomerative Hierarchical Clustering. Experiment with different settings for calculating the cluster similarity. What is a good setting?\n",
    "\n",
    "We first define which settings we want to test (the different linkage modes) and then iterate over these values in a for loop.\n",
    "Inside the loop, we create the clustering with the respective settings and plot the dendrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define the different linkage modes that we want to test\n",
    "modes = ['single', 'average', 'complete']\n",
    "\n",
    "# create a figure\n",
    "plt.figure(figsize=(20,5))\n",
    "y_axis = None\n",
    "\n",
    "# iterate over all linkage modes\n",
    "for i, mode in enumerate(modes):\n",
    "    \n",
    "    # add a subplot \n",
    "    y_axis = plt.subplot(1,4,i + 1, sharey = y_axis)\n",
    "    \n",
    "    # setup the labels\n",
    "    plt.title('Dendrogram - linkage mode: {}'.format(mode))\n",
    "    plt.xlabel('ID of student')\n",
    "    plt.ylabel('distance')\n",
    "    \n",
    "    # create the clustering\n",
    "    \n",
    "    \n",
    "    # plot the dendrogram\n",
    "\n",
    "    \n",
    "# show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 8.2.4. What does the dendrogram tell you about the distances between the different groups of students?\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 8.3. Clustering the Iris Data Set\n",
    "#### 8.3. Cluster the Iris data set using different algorithms and parameter settings. Does it make sense to normalise the data before applying the algorithms? Try to choose an algorithm and parameter setting that reproduces the original division into the three different species.\n",
    "Load the dataset as seen in the last exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the file into a dataframe\n",
    "\n",
    "\n",
    "# show the first few records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Does it make sense to normalise the data before applying the algorithms?\n",
    "Have a look at basic statistics of the dataset to check if you should apply normalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate statistics for the iris dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create clusterings with KMeans, Agglomerative Clustering and DBSCAN using different parameter settings. We compare the results using plots.\n",
    "\n",
    "As we know the correct assignment from the dataset, we can calculate the overlap between clusters and the types of flowers.\n",
    "For this calculattion, we add the cluster ids to the dataframe (using the ```join()``` function) and then group by the name of the flower and the cluster id.\n",
    "Using the ```size()``` function, we get the number of records in each of these groups, which corresponds to the overlap of the cluster with the respective flower type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# import Agglomerative Clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# import DBSCAN\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# show frequency of each type of flower\n",
    "display(iris.groupby('Name').size())\n",
    "\n",
    "# plot the correct assignment\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "# create one series per type of flower\n",
    "for name, group in iris.groupby('Name'):\n",
    "    plt.scatter(group['PetalLength'], group['PetalWidth'], label=name)\n",
    "plt.xlabel(\"Petal length\")\n",
    "plt.ylabel(\"Petal width\")\n",
    "plt.title(\"Ground Truth\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ***************************\n",
    "# KMeans\n",
    "# ***************************\n",
    "estimator = KMeans(n_clusters = 3)\n",
    "estimator.fit(iris[['PetalLength', 'PetalWidth']])\n",
    "\n",
    "# show the frequency of each type of flower in every cluster\n",
    "display(iris.join(pd.Series(estimator.labels_, name=\"KMeans\")).groupby(['Name', 'KMeans']).size())\n",
    "\n",
    "# plot the clusters\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.title(\"KMeans\")\n",
    "plt.xlabel('Petal length')\n",
    "plt.ylabel('Petal width')\n",
    "plt.scatter(iris['PetalLength'], iris['PetalWidth'], c=estimator.labels_)\n",
    "plt.show()\n",
    "\n",
    "# ***************************\n",
    "# DBSCAN\n",
    "# ***************************\n",
    "\n",
    "\n",
    "# ***************************\n",
    "# Agglomerative\n",
    "# ***************************\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 8.4. Clustering the Geo Data Set\n",
    "\n",
    "#### 8.4.1. The geo data set (provided in ILIAS) contains the coordinates (x & y) of housings in a certain area. Have a look at the data and visualize it with a scatter plot, using the ```area``` feature as colour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset into a dataframe\n",
    "\n",
    "\n",
    "# show the first few lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# create a scatter plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 8.4.2. Cluster the data using k-Means (k=3). Do the clusters represent the original areas?\n",
    "We cluster the dataset and plot again, this time using the cluster ids as colour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the clustering\n",
    "\n",
    "\n",
    "# plot again\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 8.4.3. Apply DBSCAN and play around with the epsilon. Can you reproduce the original areas using this cluster algorithm?\n",
    "\n",
    "We run DBSCAN in its default configuration first.\n",
    "Then, we systematically test different parameter settings for ```min_samples``` and ```eps```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the result of running DBSCAN with default configuration\n",
    "\n",
    "\n",
    "# test different parameter settings and plot the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 8.5. Clustering the Zoo Data Set\n",
    "#### 8.5.1. The Zoo data set describes 101 animals using 18 different attributes. The data set is provided in ILIAS as an ARFF file. Load this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import arff\n",
    "from scipy.io import arff\n",
    "\n",
    "# load the file and create a dataframe\n",
    "zoo_arff_data, zoo_arff_meta = arff.loadarff('zoo.arff')\n",
    "zoo_data = pd.DataFrame(zoo_arff_data)\n",
    "\n",
    "# solve the encoding issue in the data\n",
    "columns_with_binary_strings = zoo_data.select_dtypes('object').columns.values\n",
    "zoo_data[columns_with_binary_strings] = zoo_data[columns_with_binary_strings].apply(lambda x: x.str.decode(\"utf-8\"))\n",
    "\n",
    "zoo_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 8.5.2. Cluster the data set using Agglomerative Hierarchical Clustering. Experiment with different parameter settings in order to generate a nice species tree.\n",
    "\n",
    "We first have to encode the non-numerical features. Note that the ```type``` feature already contains a classification of the species, so we exclude it and use it to see if our results make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import preprocessing from sklean\n",
    "\n",
    "\n",
    "# specify which attributes you want to use\n",
    "\n",
    "\n",
    "# create the encoder\n",
    "\n",
    "\n",
    "# encode the selected attributes\n",
    "\n",
    "\n",
    "# show the result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can create a clustering and look at the dendrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# create the clustering\n",
    "\n",
    "# plot the dendrogram\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
