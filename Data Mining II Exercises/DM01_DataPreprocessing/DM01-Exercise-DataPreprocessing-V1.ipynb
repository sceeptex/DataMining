{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Data Preprocessing\n",
    "\n",
    "In this exercise we will mainly focus on data preprocessing. Additionally, we will do some basic classification. If you are unfamiliar with the basics of those topics, take a look at the lectures and exercises of [Data Mining I](https://dws.informatik.uni-mannheim.de/en/teaching/courses-for-master-candidates/ie-500-data-mining/).\n",
    "\n",
    "For a quick reference of how to work with pandas, you can use [this cheat sheet](http://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: The Data Set\n",
    "In the following we will work with the Data Mining Cup Data Set of 2010:\n",
    "- Download the data set from https://www.data-mining-cup.com/reviews/dmc-2010/\n",
    "- Make yourself familiar with task and features\n",
    "- Use the `pandas`-library to import the training data as a DataFrame\n",
    "- Have an initial look at the data set. Are the features parsed correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('max_columns', 100)  # show all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the pandas library to import the training data.\n",
    "# Take a look at the training data to find out which of the import methods of pandas fits best.\n",
    "# (https://pandas.pydata.org/pandas-docs/stable/reference/io.html)\n",
    "\n",
    "# --- TODO ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Data Visualisation\n",
    "Now, we inspect the data in order to find out what kinds of problems we need to tackle during preprocessing. Most importantly, we want to answer the following questions:\n",
    "- Which features have a high correlation with each other and are candidates for removal?\n",
    "- Which features are the most important ones (i.e. correlate best with the label)?\n",
    "- What other special characteristics can be found for the features of the data set? (keep the last lecture in mind!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation between features (or between a feature and the label) with pandas.\n",
    "# Here are some hints for a visualisation of the correlations:\n",
    "# https://stackoverflow.com/questions/29432629/correlation-matrix-using-pandas\n",
    "\n",
    "# --- TODO ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What else could be important in the data set? Try to think of topics treated in the lecture!\n",
    "# Check out the preprocessing-documentation of sklearn for additional ideas:\n",
    "# https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing\n",
    "\n",
    "# --- TODO ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Classification\n",
    "Before we do any preprocessing, we first build our classification pipeline. We then use it during the preprocessing to evaluate whether our modifications have an impact on the performance of the classification.\n",
    "- Complete the `evaluate_classification` function.\n",
    "  - Use NaiveBayes and DecisionTree as classification algorithms\n",
    "  - Use 10-fold cross-validation\n",
    "  - Print accuracy, precision, recall, and F1-measure\n",
    "- Use `evaluate_classification` to get some baseline results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the following function which evaluates the performance of the NaiveBayes and DecisionTree classifiers.\n",
    "\n",
    "def evaluate_classification(X, y):\n",
    "    # --- TODO ---\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Basic Preprocessing\n",
    "We start with some initial preprocessing steps. Check, whether the following modifications improve your results:\n",
    "- Experiment with different feature sets (i.e. only use some features, or discard some irrelevant features)\n",
    "- Tackle the problem of imbalanced label distributions (you might need an adapted version of `evaluate_classification`)\n",
    "- Impute missing values using the methods of the lecture (default, min, max, avg, ..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the performance metrics for feature subsets. Pick the features based on insights from the Data Visualisation.\n",
    "\n",
    "# --- TODO ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an adapted version of 'evaluate_classification' to tackle the problem of imbalanced label distributions:\n",
    "# You can either try to balance the training data during cross-validation (which is cumbersome)\n",
    "# or you check whether the classification algorithms have their own mechanisms of dealing with imbalanced labels\n",
    "\n",
    "# --- TODO ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there missing values in the data set? Try to impute them using different mechanisms.\n",
    "# Imputation with pandas: https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html\n",
    "\n",
    "# --- TODO ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Feature Generation\n",
    "Now we generate additional features to improve the classification results. Try to find features that are usefull in this shopping scenario. Check whether the generated features improve the performance of your classification.\n",
    "- Generate new features from the existing date features (ask yourself which times/days/months you usually shop)\n",
    "- Apply PCA (Principal Component Analysis) to transform the feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features from existing date features. Try to think of features that define the actual shopping behavior.\n",
    "# Use pandas to deal with dates: https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "\n",
    "# --- TODO ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the feature space using PCA and check whether the results improve.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "\n",
    "# --- TODO ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Optimisation\n",
    "Finally, try to optimise your results by tweaking individual parts of the classification process. How much better can the results get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPEN END QUESTION - try to improve your results as much as possible!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
