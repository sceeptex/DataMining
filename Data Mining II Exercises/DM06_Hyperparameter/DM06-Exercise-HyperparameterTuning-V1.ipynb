{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5: Hyperparameter Tuning\n",
    "\n",
    "This exercise is about hyperparameter tuning. To get familiar with hyperparameter tuning in scikit-learn, refer to the respective [part in the documentation](https://scikit-learn.org/stable/modules/grid_search.html).\n",
    "\n",
    "We again use the data set of the Data Mining Cup 2006. Remember: the task is to predict the attribute `gms_greater_avg` as precisely as possible. This time, we use the F1-measure of the class `1` as main performance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Warm-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "RANDOM_STATE = 42  # use this random state to make your experiments consistent\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the pandas library to import the training data similarly to exercise 2.\n",
    "\n",
    "# --- TODO ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 50:50 train-test-split and assign the results to the variables X_train, X_test and y_train, y_test\n",
    "\n",
    "# --- TODO ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "estimators = {\n",
    "    'Naive Bayes': GaussianNB().fit(X_train, y_train),\n",
    "    'K-NN': KNeighborsClassifier(n_neighbors=1).fit(X_train, y_train),\n",
    "    'SVC': SVC(random_state=RANDOM_STATE).fit(X_train, y_train)\n",
    "}\n",
    "\n",
    "# Implement the `evaluate_estimators` function so that it returns precision, recall, and F1-measure\n",
    "# of the class 1 on the test set for the classifiers given in `estimators`.\n",
    "\n",
    "def evaluate_estimators(estimators, X, y_true):\n",
    "    # TODO\n",
    "    pass\n",
    "        \n",
    "evaluate_estimators(estimators, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tune_params = {\n",
    "    'K-NN': {\n",
    "        'n_neighbors': [1, 3, 5, 10]\n",
    "    },\n",
    "    'SVC': {\n",
    "        'C': [.001, .01, .1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'tol': [1e-2, 1e-3, 1e-4],\n",
    "        'class_weight': ['balanced', None],\n",
    "    }\n",
    "}\n",
    "\n",
    "# Run a grid search with the parameters given in `tune_params` with F1-measure as optimization objective.\n",
    "# For the best estimator, print the parameters and evaluate it with the `evaluate_estimators` function.\n",
    "# HINT: Take a look at https://scikit-learn.org/stable/modules/grid_search.html for infos about grid search.\n",
    "\n",
    "# --- TODO ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Successive Halving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Now run a successive halving grid search with the parameters given in `tune_params` with F1-measure as objective.\n",
    "# Use a `min_resources` of 200 and a `factor` of 2.\n",
    "# Again, print parameters of the best estimator and evaluate it with the `evaluate_estimators` function.\n",
    "# HINT: Examples for halving grid search: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html#sklearn.model_selection.HalvingGridSearchCV\n",
    "# HINT: To use successive halving, you need a scikit-learn version of 0.24.1 or higher\n",
    "#       -> run a cell with `!pip install scikit-learn==0.24.1` and restart the notebook.\n",
    "\n",
    "# --- TODO ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "bayes_tune_params = {\n",
    "    'K-NN': {\n",
    "        'n_neighbors': (1, 10)\n",
    "    },\n",
    "    'SVC': {\n",
    "        'C': (1e-3, 1e+3, 'log-uniform'),\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'tol': (1e-4, 1e-2, 'log-uniform'),\n",
    "        'class_weight': ['balanced', None],\n",
    "    }\n",
    "}\n",
    "\n",
    "# Now run a bayesian search with the parameters given in `bayes_tune_params` with F1-measure as objective.\n",
    "# Use a `n_iter` of 15.\n",
    "# Again, print parameters of the best estimator and evaluate it with the `evaluate_estimators` function.\n",
    "# HINT: Use scikit-optimize for bayesian search (https://scikit-optimize.github.io/stable/auto_examples/bayesian-optimization.html)\n",
    "# HINT: Currently, BayesSearchCV does not work with scikit-learn version of 0.24.1. Use version 0.23.2 instead.\n",
    "#       -> run a cell with `!pip install scikit-learn==0.23.2` and restart the notebook.\n",
    "\n",
    "# --- TODO ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
