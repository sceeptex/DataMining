{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- SOLUTION ---\n",
    "\n",
    "HINT: These solutions only give an impression on how the problems can be tackled. They are neither the best possible solutions nor are they always complete. You are invited to find approaches that outperform those given in the solutions and present them to your fellow students."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5: Hyperparameter Tuning\n",
    "\n",
    "This exercise is about hyperparameter tuning. To get familiar with hyperparameter tuning in scikit-learn, refer to the respective [part in the documentation](https://scikit-learn.org/stable/modules/grid_search.html).\n",
    "\n",
    "We again use the data set of the Data Mining Cup 2006. Remember: the task is to predict the attribute `gms_greater_avg` as precisely as possible. This time, we use the F1-measure of the class `1` as main performance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Warm-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "RANDOM_STATE = 42  # use this random state to make your experiments consistent\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the pandas library to import the training data similarly to exercise 2.\n",
    "\n",
    "# --- SOLUTION ---\n",
    "df = pd.read_csv('dmc2006/dmc2006_train.txt', sep='\\t', encoding='cp1252').drop(columns=['auct_id', 'gms', 'listing_title', 'listing_subtitle', 'listing_start_date', 'listing_end_date'])\n",
    "X, y = df.drop(columns='gms_greater_avg'), df['gms_greater_avg']\n",
    "\n",
    "# converting columns to have reasonable format\n",
    "X = pd.get_dummies(X, columns=['item_leaf_category_name'])\n",
    "boolean_columns = [k for k, v in X.dtypes.items() if v == np.object]\n",
    "X[boolean_columns] = X[boolean_columns].apply(lambda row: [1 if x == 'Y' else 0 for x in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 50:50 train-test-split and assign the results to the variables X_train, X_test and y_train, y_test\n",
    "\n",
    "# --- SOLUTION ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5, random_state=RANDOM_STATE, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes: P=0.63 R=0.29 F1=0.39\n",
      "K-NN: P=0.60 R=0.59 F1=0.60\n",
      "SVC: P=0.63 R=0.29 F1=0.40\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "estimators = {\n",
    "    'Naive Bayes': GaussianNB().fit(X_train, y_train),\n",
    "    'K-NN': KNeighborsClassifier(n_neighbors=1).fit(X_train, y_train),\n",
    "    'SVC': SVC(random_state=RANDOM_STATE).fit(X_train, y_train)\n",
    "}\n",
    "\n",
    "# Implement the `evaluate_estimators` function so that it returns precision, recall, and F1-measure\n",
    "# of the class 1 on the test set for the classifiers given in `estimators`.\n",
    "\n",
    "# --- SOLUTION ---\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def evaluate_estimators(estimators, X, y_true):\n",
    "    for e_name, e in estimators.items():\n",
    "        p, r, f1, _ = precision_recall_fscore_support(y_true, e.predict(X), average='binary')\n",
    "        print(f'{e_name}: P={p:.2f} R={r:.2f} F1={f1:.2f}')\n",
    "        \n",
    "        \n",
    "evaluate_estimators(estimators, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-NN best parameters: {'n_neighbors': 3}\n",
      "SVC best parameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 'auto', 'tol': 0.01}\n",
      "K-NN: P=0.60 R=0.58 F1=0.59\n",
      "SVC: P=0.53 R=0.69 F1=0.60\n",
      "CPU times: user 3min 49s, sys: 1.73 s, total: 3min 51s\n",
      "Wall time: 3min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tune_params = {\n",
    "    'K-NN': {\n",
    "        'n_neighbors': [1, 3, 5, 10]\n",
    "    },\n",
    "    'SVC': {\n",
    "        'C': [.001, .01, .1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'tol': [1e-2, 1e-3, 1e-4],\n",
    "        'class_weight': ['balanced', None],\n",
    "    }\n",
    "}\n",
    "\n",
    "# Run a grid search with the parameters given in `tune_params` with F1-measure as optimization objective.\n",
    "# For the best estimator, print the parameters and evaluate it with the `evaluate_estimators` function.\n",
    "# HINT: Take a look at https://scikit-learn.org/stable/modules/grid_search.html for infos about grid search.\n",
    "\n",
    "# --- SOLUTION ---\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def grid_search_estimator(e_name, e, param_grid, X, y):\n",
    "    gscv = GridSearchCV(e, param_grid, scoring='f1', cv=10).fit(X, y)\n",
    "    print(f'{e_name} best parameters: {gscv.best_params_}')\n",
    "    return gscv.best_estimator_\n",
    "\n",
    "grid_estimators = {e_name: grid_search_estimator(e_name, e, tune_params[e_name], X_train, y_train)\n",
    "                   for e_name, e in estimators.items()\n",
    "                   if e_name in tune_params}\n",
    "\n",
    "evaluate_estimators(grid_estimators, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Successive Halving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-NN best parameters: {'n_neighbors': 5}\n",
      "SVC best parameters: {'C': 100, 'class_weight': 'balanced', 'gamma': 'scale', 'tol': 0.01}\n",
      "K-NN: P=0.59 R=0.55 F1=0.57\n",
      "SVC: P=0.61 R=0.35 F1=0.44\n",
      "CPU times: user 1min 30s, sys: 1.37 s, total: 1min 32s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Now run a successive halving grid search with the parameters given in `tune_params` with F1-measure as objective.\n",
    "# Use a `min_resources` of 200 and a `factor` of 2.\n",
    "# Again, print parameters of the best estimator and evaluate it with the `evaluate_estimators` function.\n",
    "# HINT: Examples for halving grid search: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html#sklearn.model_selection.HalvingGridSearchCV\n",
    "# HINT: To use successive halving, you need a scikit-learn version of 0.24.1 or higher\n",
    "#       -> run a cell with `!pip install scikit-learn==0.24.1` and restart the notebook.\n",
    "\n",
    "# --- SOLUTION ---\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv  # enable it first, as it is still experimental feature\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "# hint: only works with sklearn >= 0.24.1\n",
    "def halving_search_estimator(e_name, e, param_grid, X, y):\n",
    "    hgscv = HalvingGridSearchCV(e, param_grid, scoring='f1', factor=2, min_resources=200, cv=10, random_state=RANDOM_STATE).fit(X, y)\n",
    "    print(f'{e_name} best parameters: {hgscv.best_params_}')\n",
    "    return hgscv.best_estimator_\n",
    "\n",
    "halving_estimators = {e_name: halving_search_estimator(e_name, e, tune_params[e_name], X_train, y_train)\n",
    "                   for e_name, e in estimators.items()\n",
    "                   if e_name in tune_params}\n",
    "\n",
    "evaluate_estimators(halving_estimators, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: As expected, the heuristic does not deliver optimal results. However, we get a decently tuned SVM in less than half of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-NN best parameters: OrderedDict([('n_neighbors', 1)])\n",
      "SVC best parameters: OrderedDict([('C', 65.08969218717925), ('class_weight', 'balanced'), ('gamma', 'auto'), ('tol', 0.01)])\n",
      "K-NN: P=0.60 R=0.59 F1=0.60\n",
      "SVC: P=0.58 R=0.43 F1=0.49\n",
      "CPU times: user 2min 49s, sys: 5.43 s, total: 2min 55s\n",
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bayes_tune_params = {\n",
    "    'K-NN': {\n",
    "        'n_neighbors': (1, 10)\n",
    "    },\n",
    "    'SVC': {\n",
    "        'C': (1e-3, 1e+3, 'log-uniform'),\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'tol': (1e-4, 1e-2, 'log-uniform'),\n",
    "        'class_weight': ['balanced', None],\n",
    "    }\n",
    "}\n",
    "\n",
    "# Now run a bayesian search with the parameters given in `bayes_tune_params` with F1-measure as objective.\n",
    "# Use a `n_iter` of 15.\n",
    "# Again, print parameters of the best estimator and evaluate it with the `evaluate_estimators` function.\n",
    "# HINT: Use scikit-optimize for bayesian search (https://scikit-optimize.github.io/stable/auto_examples/bayesian-optimization.html)\n",
    "# HINT: Currently, BayesSearchCV does not work with scikit-learn version of 0.24.1. Use version 0.23.2 instead.\n",
    "#       -> run a cell with `!pip install scikit-learn==0.23.2` and restart the notebook.\n",
    "\n",
    "# --- SOLUTION ---\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# hint: install scikit-optimize first\n",
    "# hint: use sklearn==0.23.2 and restart notebook after installation\n",
    "def bayes_search_estimator(e_name, e, param_grid, X, y):\n",
    "    bscv = BayesSearchCV(e, search_spaces=param_grid, scoring='f1', n_iter=15, cv=10, random_state=RANDOM_STATE).fit(X, y)\n",
    "    print(f'{e_name} best parameters: {bscv.best_params_}')\n",
    "    return bscv.best_estimator_\n",
    "\n",
    "bayes_estimators = {e_name: bayes_search_estimator(e_name, e, bayes_tune_params[e_name], X_train, y_train)\n",
    "                   for e_name, e in estimators.items()\n",
    "                   if e_name in bayes_tune_params}\n",
    "\n",
    "evaluate_estimators(bayes_estimators, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: As expected, the bayesian search does not deliver optimal results. But we get even better results than with successive halving and we can easily control the runtime of the optimization with the `n_iter` parameter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
